import MLJBase

using DataFrames
using MLLabelUtils
using LinearAlgebra
using MLJ

using Flux: onehotbatch, onecold

"""
Variables associated with the Task Balanced Multimodal Feature Selection Classifier.
"""
mutable struct TBMFSClassifier <: MLJBase.Deterministic
    Xcut::Array{UnitRange{Int64},1} # How to "cut" X into multimodal data
    C::Float64                      # SVM Regularization
    Î±â‚˜::Array{Float64, 1}           # Modality reconstruction hyperparameter
    Î³â‚˜::Array{Float64, 1}           # Row-sparsity hyperparamter for each Bâ‚˜
    r::Int64                        # Matrix factorization parameter (inner dimension)
    Î¼::Float64                      # Augmented Lagrangian penalty parameter
    Ï::Float64                      # Scaling factor on Î¼
    maxiter::Int64                  # Maximum number of iterations
    tol::Float64                    # Stopping criterion
end

"""
Default constructor for the Task Balanced Multimodal Feture Selection Classifier.

TODO: Add checks to hyperparameters.
"""
function TBMFSClassifier(; Xcut=missing, C=1.0, Î±â‚˜=missing, Î³â‚˜=missing, r=missing, Î¼=0.001, Ï=1.2, maxiter=50, tol=1e-5)
    model = TBMFSClassifier(Xcut, C, Î±â‚˜, Î³â‚˜, r, Î¼, Ï, maxiter, tol)
    return model
end

"""
Calculate Task Balanced Multimodal Feature Selection objective loss. Equation (5)
"""
function objloss!(objğ“›s, i, Xâ‚˜, Y_hot, W, b, Z, Bâ‚˜, Î±â‚˜, Î³â‚˜, C)
    for m in 1:length(Xâ‚˜)
        objğ“›s[i] += Î±â‚˜[m] * l21norm(Xâ‚˜[m] - Bâ‚˜[m]*Z)
        objğ“›s[i] += Î³â‚˜[m] * l21norm(Bâ‚˜[m])
    end
    objğ“›s[i] += 0.5 * norm(W)^2
    objğ“›s[i] += C * sum(max.(1 .- (W' * Z .+ b) .* Y_hot, 0))
end

"""
Calculates the Lagrangian loss. Equation (9)
"""
function loss!(ğ“›s, Es, Fs, BÌ‚s, ZÌ‚s, i, Xâ‚˜, Y_hot, E, W, b, Z, ZÌ‚, Fâ‚˜, Bâ‚˜, BÌ‚â‚˜, Î˜â‚˜, Î›â‚˜, Î©, Î·, Î±â‚˜, Î³â‚˜, C, Î¼)
    ğ“›s[i] = 0.0
    Es[i] = 0.0
    Fs[i] = 0.0
    BÌ‚s[i] = 0.0
    ZÌ‚s[i] = 0.0

    ğ“›s[i] += C * sum(max.(Y_hot .* E, 0))
    ğ“›s[i] += 0.5 * norm(W)^2
    ğ“›s[i] += Î¼/2.0 * norm(E .- Y_hot .+ W'*Z .+ b .+ Î·/Î¼)^2
    ğ“›s[i] += Î¼/2.0 * norm(Z - ZÌ‚ + Î©/Î¼)^2

    Es[i] += norm(E .- Y_hot .+ W' * Z .+ b)
    ZÌ‚s[i] += norm(Z - ZÌ‚)

    for m in 1:length(Xâ‚˜)
        ğ“›s[i] += Î±â‚˜[m] * l21norm(Fâ‚˜[m])
        ğ“›s[i] += Î³â‚˜[m] * l21norm(BÌ‚â‚˜[m])
        ğ“›s[i] += Î¼/2.0 * norm(Fâ‚˜[m] - Xâ‚˜[m] + Bâ‚˜[m]*Z + Î˜â‚˜[m]/Î¼)^2
        ğ“›s[i] += Î¼/2.0 * norm(Bâ‚˜[m] - BÌ‚â‚˜[m] + Î›â‚˜[m]/Î¼)^2

        Fs[i] += norm(Fâ‚˜[m] - Xâ‚˜[m] + Bâ‚˜[m]*Z)
        BÌ‚s[i] += norm(Bâ‚˜[m] - BÌ‚â‚˜[m])
    end
end

"""
Calculates the â„“_{2,1} norm for the matrix X.
"""
function l21norm(X)
    res = 0.0
    for row âˆˆ eachrow(X)
        res += norm(row, 2)
    end
    return res
end

"""
Initializes variables for optimization.

Note that all the variables in X come in concatenated together.
Thus, they must be "cut" into multiple modalities.
"""
function init_var(model::TBMFSClassifier, X, Y)
    K = MLJBase.nrows(classes(Y[1]))
    x = MLJBase.matrix(X)
    N, _ = size(x)

    Xâ‚˜ = [x[:,cut]' for cut in model.Xcut]
    Xâ‚˜ = [vcat(xâ‚˜, ones(size(xâ‚˜)[2])') for xâ‚˜ in Xâ‚˜] # Add intercept to each modality.
    Y_onehot = onehotbatch(Y, classes(Y[1])) .* 2.0 .- 1.0

    M = length(Xâ‚˜)
    dâ‚˜ = [size(Xâ‚˜[m])[1] for m in 1:M]

    E = randn(K, N)
    W = randn(model.r, K)
    b = randn(K)
    Z = randn(model.r, N)
    ZÌ‚ = randn(model.r, N)
    Fâ‚˜ = [randn(dâ‚˜[i], N) for i in 1:M]
    Bâ‚˜ = [randn(dâ‚˜[i], model.r) for i in 1:M]
    BÌ‚â‚˜ = [randn(dâ‚˜[i], model.r) for i in 1:M]

    Î˜â‚˜ = [zeros(dâ‚˜[i], N) for i in 1:M]
    Î›â‚˜ = [zeros(dâ‚˜[i], model.r) for i in 1:M]
    Î© = zeros(model.r, N)
    Î· = zeros(K, N)

    return Xâ‚˜, Y_onehot, E, W, b, Z, ZÌ‚, Fâ‚˜, Bâ‚˜, BÌ‚â‚˜, Î˜â‚˜, Î›â‚˜, Î©, Î·, N, M
end

"""
Updates each w_k. Equation (11)
"""
function update_W!(W, Y_hot, E, b, Z, Î·, Î¼)
    _, K = size(W)
    r, N = size(Z)
    âˆ‘záµ¢záµ¢áµ€ = zeros(r, r)

    for i in 1:N
        âˆ‘záµ¢záµ¢áµ€ += Z[:,i] * Z[:,i]'
    end

    #W[:] = (âˆ‘záµ¢záµ¢áµ€ + I/Î¼)' \ ((Y_hot .- E .- b .- Î·/Î¼) * Z')'
    W[:] = (((Y_hot .- E .- b .- Î·/Î¼) * Z') * pinv(âˆ‘záµ¢záµ¢áµ€ + I/Î¼))'
end

"""
Updates each b_k. Equation (12)
"""
function update_b!(b, Y_hot, E, W, Z, Î·, Î¼)
    K, N = size(Y_hot)

    b[:] = sum(Y_hot .- E .- W' * Z .- Î· / Î¼, dims=2) ./ N
end

"""
Updates the each e_{im}. Equation (14)
"""
function update_E!(E, Y_hot, W, b, Z, Î·, C, Î¼)
    S = Y_hot .- (W'*Z  .+ b) - Î·/Î¼

    gt = (Y_hot .* S) .> C/Î¼
    mid = 0 .<= (Y_hot .* S) .<= C/Î¼

    E[:] = S .* .!mid - gt .* Y_hot .* (C/Î¼)
end

"""
Updates Z. Equation (16)
"""
function update_Z!(Z, Xâ‚˜, Y_hot, E, W, b, ZÌ‚, Fâ‚˜, Bâ‚˜, Î˜â‚˜, Î©, Î·, Î¼)
    M = length(Xâ‚˜)
    r, N = size(Z)
    _, K = size(W)

    Tâ‚˜ = [x - f - Î¸/Î¼ for (x, f, Î¸) in zip(Xâ‚˜, Fâ‚˜, Î˜â‚˜)]
    U = Y_hot .- E .- b .- Î·/Î¼

    âˆ‘Bâ‚˜áµ€Bâ‚˜ = zeros(r, r)
    âˆ‘Bâ‚˜áµ€T = zeros(r, N)
    âˆ‘wâ‚–wâ‚–áµ€ = zeros(r, r)
    âˆ‘wâ‚–U = W * U

    for m in 1:M
        âˆ‘Bâ‚˜áµ€Bâ‚˜ += Bâ‚˜[m]' * Bâ‚˜[m]
        âˆ‘Bâ‚˜áµ€T += Bâ‚˜[m]' * Tâ‚˜[m]
    end

    for k in 1:K
        âˆ‘wâ‚–wâ‚–áµ€ += W[:,k] * W[:,k]'
    end

    #Z[:] = (âˆ‘Bâ‚˜áµ€Bâ‚˜ + âˆ‘wâ‚–wâ‚–áµ€ + I) \ (âˆ‘Bâ‚˜áµ€T + âˆ‘wâ‚–U + ZÌ‚ - Î©/Î¼)
    Z[:] = pinv(âˆ‘Bâ‚˜áµ€Bâ‚˜ + âˆ‘wâ‚–wâ‚–áµ€ + I) * (âˆ‘Bâ‚˜áµ€T + âˆ‘wâ‚–U + ZÌ‚ - Î©/Î¼)
end

"""
Updates ZÌ‚. Equation (18)
"""
function update_ZÌ‚!(ZÌ‚, Z, Î©, Î¼)
    U, Î£, V = svd(Z + Î©/Î¼)
    ZÌ‚[:] = U*V'
end

"""
Updates Fâ‚˜. Equation (20)
"""
function update_Fâ‚˜!(Fâ‚˜, Xâ‚˜, Z, Bâ‚˜, Î˜â‚˜, Î¼, Î±â‚˜, Lâ‚˜)
    Lâ‚˜ = Xâ‚˜ - Bâ‚˜*Z - Î˜â‚˜/Î¼
    threshold = [max(1 - Î±â‚˜/(Î¼*norm(lâ±) + 1e-12), 0) for lâ± âˆˆ eachrow(Lâ‚˜)]
    Fâ‚˜[:] = Lâ‚˜ .* threshold
end

"""
Updates BÌ‚â‚˜. Equation (22)
"""
function update_BÌ‚â‚˜!(BÌ‚â‚˜, Bâ‚˜, Î›â‚˜, Î¼, Î³â‚˜)
    Oâ‚˜ = Bâ‚˜ + Î›â‚˜/Î¼
    threshold = [max(1 - Î³â‚˜/(Î¼*norm(oâ±) + 1e-12), 0) for oâ± âˆˆ eachrow(Oâ‚˜)]
    BÌ‚â‚˜[:] = Oâ‚˜ .* threshold
end

"""
Updates Bâ‚˜. Equation (24)
"""
function update_Bâ‚˜!(Bâ‚˜, Xâ‚˜, Z, Fâ‚˜, BÌ‚â‚˜, Î˜â‚˜, Î›â‚˜, Î¼)
    #Bâ‚˜[:] = ((Z*Z' + I) \ (-(Fâ‚˜-Xâ‚˜+Î˜â‚˜/Î¼)*Z' + (BÌ‚â‚˜ - Î›â‚˜/Î¼))')' 
    Bâ‚˜[:] =  (-(Fâ‚˜-Xâ‚˜+Î˜â‚˜/Î¼)*Z' + (BÌ‚â‚˜ - Î›â‚˜/Î¼)) * pinv(Z*Z' + I)
end

"""
Fits a Task Balanced Multimodal Feature Selection Classifier from X --> Y.

NOTE: checking the Lagrangian loss function (commented out) before 
and after an update is a nice way to debug a complex multiblock ADMM 
algorithm such as this one. 

TODO: decrease the verbosity of these checks.
"""
function MLJBase.fit(model::TBMFSClassifier, verbosity::Integer, X, y)
    Xâ‚˜, Y_hot, E, W, b, Z, ZÌ‚, Fâ‚˜, Bâ‚˜, BÌ‚â‚˜, Î˜â‚˜, Î›â‚˜, Î©, Î·, N, M = init_var(model, X, y)

    C = model.C
    Î±â‚˜ = model.Î±â‚˜
    Î³â‚˜ = model.Î³â‚˜
    Î¼ = model.Î¼

    Lâ‚˜ = [zeros(size(x)) for x in Xâ‚˜]

    objğ“›s = zeros(model.maxiter)
    ğ“›s = zeros(model.maxiter)
    Es = zeros(model.maxiter)
    Fs = zeros(model.maxiter)
    BÌ‚s = zeros(model.maxiter)
    ZÌ‚s = zeros(model.maxiter)
    prev_ğ“› = Inf

    for i in 1:model.maxiter
        for m in 1:M
            # Update Fâ‚˜
            # loss!(ğ“›s, Es, Fs, BÌ‚s, ZÌ‚s, i, Xâ‚˜, Y_hot, E, W, b, Z, ZÌ‚, Fâ‚˜, Bâ‚˜, BÌ‚â‚˜, Î˜â‚˜, Î›â‚˜, Î©, Î·, Î±â‚˜, Î³â‚˜, C, Î¼)
            # l1 = ğ“›s[i]
            update_Fâ‚˜!(Fâ‚˜[m], Xâ‚˜[m], Z, Bâ‚˜[m], Î˜â‚˜[m], Î¼, Î±â‚˜[m], Lâ‚˜)
            # loss!(ğ“›s, Es, Fs, BÌ‚s, ZÌ‚s, i, Xâ‚˜, Y_hot, E, W, b, Z, ZÌ‚, Fâ‚˜, Bâ‚˜, BÌ‚â‚˜, Î˜â‚˜, Î›â‚˜, Î©, Î·, Î±â‚˜, Î³â‚˜, C, Î¼)
            # l2 = ğ“›s[i]
            # if verbosity>10 println("checking Fâ‚˜ ", l2, " <= ", l1, " ", l2 <= l1); @assert l2 <= l1 + 1e-8 end

            # Update Bâ‚˜
            # loss!(ğ“›s, Es, Fs, BÌ‚s, ZÌ‚s, i, Xâ‚˜, Y_hot, E, W, b, Z, ZÌ‚, Fâ‚˜, Bâ‚˜, BÌ‚â‚˜, Î˜â‚˜, Î›â‚˜, Î©, Î·, Î±â‚˜, Î³â‚˜, C, Î¼)
            # l1 = ğ“›s[i]
            update_Bâ‚˜!(Bâ‚˜[m], Xâ‚˜[m], Z, Fâ‚˜[m], BÌ‚â‚˜[m], Î˜â‚˜[m], Î›â‚˜[m], Î¼)
            # loss!(ğ“›s, Es, Fs, BÌ‚s, ZÌ‚s, i, Xâ‚˜, Y_hot, E, W, b, Z, ZÌ‚, Fâ‚˜, Bâ‚˜, BÌ‚â‚˜, Î˜â‚˜, Î›â‚˜, Î©, Î·, Î±â‚˜, Î³â‚˜, C, Î¼)
            # l2 = ğ“›s[i]
            # if verbosity>10 println("checking Bâ‚˜ ", l2, " <= ", l1, " ", l2 <= l1); @assert l2 <= l1 + 1e-8 end

            # Update BÌ‚â‚˜
            # loss!(ğ“›s, Es, Fs, BÌ‚s, ZÌ‚s, i, Xâ‚˜, Y_hot, E, W, b, Z, ZÌ‚, Fâ‚˜, Bâ‚˜, BÌ‚â‚˜, Î˜â‚˜, Î›â‚˜, Î©, Î·, Î±â‚˜, Î³â‚˜, C, Î¼)
            # l1 = ğ“›s[i]
            update_BÌ‚â‚˜!(BÌ‚â‚˜[m], Bâ‚˜[m], Î›â‚˜[m], Î¼, Î³â‚˜[m])
            # loss!(ğ“›s, Es, Fs, BÌ‚s, ZÌ‚s, i, Xâ‚˜, Y_hot, E, W, b, Z, ZÌ‚, Fâ‚˜, Bâ‚˜, BÌ‚â‚˜, Î˜â‚˜, Î›â‚˜, Î©, Î·, Î±â‚˜, Î³â‚˜, C, Î¼)
            # l2 = ğ“›s[i]
            # if verbosity>10 println("checking BÌ‚â‚˜ ", l2, " <= ", l1, " ", l2 <= l1); @assert l2 <= l1 + 1e-8 end
        end

        # loss!(ğ“›s, Es, Fs, BÌ‚s, ZÌ‚s, i, Xâ‚˜, Y_hot, E, W, b, Z, ZÌ‚, Fâ‚˜, Bâ‚˜, BÌ‚â‚˜, Î˜â‚˜, Î›â‚˜, Î©, Î·, Î±â‚˜, Î³â‚˜, C, Î¼)
        # l1 = ğ“›s[i]
        update_E!(E, Y_hot, W, b, Z, Î·, C, Î¼)
        # loss!(ğ“›s, Es, Fs, BÌ‚s, ZÌ‚s, i, Xâ‚˜, Y_hot, E, W, b, Z, ZÌ‚, Fâ‚˜, Bâ‚˜, BÌ‚â‚˜, Î˜â‚˜, Î›â‚˜, Î©, Î·, Î±â‚˜, Î³â‚˜, C, Î¼)
        # l2 = ğ“›s[i]
        # if verbosity>10 println("checking E ", l2, " <= ", l1, " ", l2 <= l1); @assert l2 <= l1 + 1e-8 end

        # loss!(ğ“›s, Es, Fs, BÌ‚s, ZÌ‚s, i, Xâ‚˜, Y_hot, E, W, b, Z, ZÌ‚, Fâ‚˜, Bâ‚˜, BÌ‚â‚˜, Î˜â‚˜, Î›â‚˜, Î©, Î·, Î±â‚˜, Î³â‚˜, C, Î¼)
        # l1 = ğ“›s[i]
        update_Z!(Z, Xâ‚˜, Y_hot, E, W, b, ZÌ‚, Fâ‚˜, Bâ‚˜, Î˜â‚˜, Î©, Î·, Î¼)
        # loss!(ğ“›s, Es, Fs, BÌ‚s, ZÌ‚s, i, Xâ‚˜, Y_hot, E, W, b, Z, ZÌ‚, Fâ‚˜, Bâ‚˜, BÌ‚â‚˜, Î˜â‚˜, Î›â‚˜, Î©, Î·, Î±â‚˜, Î³â‚˜, C, Î¼)
        # l2 = ğ“›s[i]
        # if verbosity>10 println("checking Z ", l2, " <= ", l1, " ", l2 <= l1); @assert l2 <= l1 + 1e-8 end

        # loss!(ğ“›s, Es, Fs, BÌ‚s, ZÌ‚s, i, Xâ‚˜, Y_hot, E, W, b, Z, ZÌ‚, Fâ‚˜, Bâ‚˜, BÌ‚â‚˜, Î˜â‚˜, Î›â‚˜, Î©, Î·, Î±â‚˜, Î³â‚˜, C, Î¼)
        # l1 = ğ“›s[i]
        update_ZÌ‚!(ZÌ‚, Z, Î©, Î¼)
        # loss!(ğ“›s, Es, Fs, BÌ‚s, ZÌ‚s, i, Xâ‚˜, Y_hot, E, W, b, Z, ZÌ‚, Fâ‚˜, Bâ‚˜, BÌ‚â‚˜, Î˜â‚˜, Î›â‚˜, Î©, Î·, Î±â‚˜, Î³â‚˜, C, Î¼)
        # l2 = ğ“›s[i]
        # if verbosity>10 println("checking ZÌ‚ ", l2, " <= ", l1, " ", l2 <= l1) end; #@assert l2 <= l1 + 1e-8 end

        # loss!(ğ“›s, Es, Fs, BÌ‚s, ZÌ‚s, i, Xâ‚˜, Y_hot, E, W, b, Z, ZÌ‚, Fâ‚˜, Bâ‚˜, BÌ‚â‚˜, Î˜â‚˜, Î›â‚˜, Î©, Î·, Î±â‚˜, Î³â‚˜, C, Î¼)
        # l1 = ğ“›s[i]
        update_W!(W, Y_hot, E, b, Z, Î·, Î¼)
        # loss!(ğ“›s, Es, Fs, BÌ‚s, ZÌ‚s, i, Xâ‚˜, Y_hot, E, W, b, Z, ZÌ‚, Fâ‚˜, Bâ‚˜, BÌ‚â‚˜, Î˜â‚˜, Î›â‚˜, Î©, Î·, Î±â‚˜, Î³â‚˜, C, Î¼)
        # l2 = ğ“›s[i]
        # if verbosity>10 println("checking W ", l2, " <= ", l1, " ", l2 <= l1); @assert l2 <= l1 + 1e-8 end

        # loss!(ğ“›s, Es, Fs, BÌ‚s, ZÌ‚s, i, Xâ‚˜, Y_hot, E, W, b, Z, ZÌ‚, Fâ‚˜, Bâ‚˜, BÌ‚â‚˜, Î˜â‚˜, Î›â‚˜, Î©, Î·, Î±â‚˜, Î³â‚˜, C, Î¼)
        # l1 = ğ“›s[i]
        update_b!(b, Y_hot, E, W, Z, Î·, Î¼)
        # loss!(ğ“›s, Es, Fs, BÌ‚s, ZÌ‚s, i, Xâ‚˜, Y_hot, E, W, b, Z, ZÌ‚, Fâ‚˜, Bâ‚˜, BÌ‚â‚˜, Î˜â‚˜, Î›â‚˜, Î©, Î·, Î±â‚˜, Î³â‚˜, C, Î¼)
        # l2 = ğ“›s[i]
        # if verbosity>10 println("checking b ", l2, " <= ", l1, " ", l2 <= l1); @assert l2 <= l1 + 1e-8 end

        for m in 1:M
            # Update Î˜â‚˜
            Î˜â‚˜[m] = Î˜â‚˜[m] + Î¼ * (Fâ‚˜[m] - Xâ‚˜[m] + Bâ‚˜[m]*Z)
            # Update Î›â‚˜
            Î›â‚˜[m] = Î›â‚˜[m] + Î¼ * (Bâ‚˜[m] - BÌ‚â‚˜[m])
        end
        # Update Î·
        Î· = Î· + Î¼ * (E .- Y_hot .+ W' * Z .+ b)
        # Update Î©
        Î© = Î© + Î¼ * (Z - ZÌ‚)

        # Update Î¼
        Î¼ = Î¼*model.Ï

        loss!(ğ“›s, Es, Fs, BÌ‚s, ZÌ‚s, i, Xâ‚˜, Y_hot, E, W, b, Z, ZÌ‚, Fâ‚˜, Bâ‚˜, BÌ‚â‚˜, Î˜â‚˜, Î›â‚˜, Î©, Î·, Î±â‚˜, Î³â‚˜, C, Î¼)
        objloss!(objğ“›s, i, Xâ‚˜, Y_hot, W, b, Z, Bâ‚˜, Î±â‚˜, Î³â‚˜, C)

        if verbosity>5 println("LOSS: ", objğ“›s[i]) end
        if abs(prev_ğ“› - ğ“›s[i]) < model.tol
            break
        end
        prev_ğ“› = ğ“›s[i]
    end

    fitresult = (Bâ‚˜, W, b, classes(y[1]))
    cache = missing
    report = (losses=(objğ“›s, ğ“›s, Es, Fs, BÌ‚s, ZÌ‚s))

    return fitresult, cache, report
end

"""
Given new multimodal data (in Xnew) give a classification prediction
using the fitresult.
"""
function MLJBase.predict(model::TBMFSClassifier, fitresult, Xnew)
    DEBUG=false
    xnew = MLJBase.matrix(Xnew)

    Bâ‚˜, W, b, c = fitresult

    Xnewâ‚˜ = [xnew[:,cut]' for cut in model.Xcut]
    Xnewâ‚˜ = [vcat(xnewâ‚˜, ones(size(xnewâ‚˜)[2])') for xnewâ‚˜ in Xnewâ‚˜]

    Znew = zeros(model.r, size(xnew)[1])

    for m in 1:length(Xnewâ‚˜)
        Zpartial = model.Î±â‚˜[m] * pinv(Bâ‚˜[m]) * Xnewâ‚˜[m]
        if DEBUG
            display(Zpartial)
        end
        Znew += Zpartial
    end
    Znew = Znew ./ sum(model.Î±â‚˜)
    pred = W'*Znew .+ b

    return onecold(pred, c)
end
